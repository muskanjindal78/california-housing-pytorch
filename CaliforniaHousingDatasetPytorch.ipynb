{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcE-4ykvLc7m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsYI0uTKgHGm",
        "outputId": "f2c20224-debb-49de-9f50-2a75f764513a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7951927381d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "california_housing = datasets.fetch_california_housing()\n",
        "california_housing"
      ],
      "metadata": {
        "id": "GbbARkgCLtzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46250795-6850-4728-8a24-09c087b44208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "           37.88      , -122.23      ],\n",
              "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "           37.86      , -122.22      ],\n",
              "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "           37.85      , -122.24      ],\n",
              "        ...,\n",
              "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "           39.43      , -121.22      ],\n",
              "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "           39.43      , -121.32      ],\n",
              "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "           39.37      , -121.24      ]]),\n",
              " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
              " 'frame': None,\n",
              " 'target_names': ['MedHouseVal'],\n",
              " 'feature_names': ['MedInc',\n",
              "  'HouseAge',\n",
              "  'AveRooms',\n",
              "  'AveBedrms',\n",
              "  'Population',\n",
              "  'AveOccup',\n",
              "  'Latitude',\n",
              "  'Longitude'],\n",
              " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = california_housing.data.shape[1]\n",
        "print(f'Number of features: {num_features}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PCqOyINNaZb",
        "outputId": "2bac9a67-a42a-4e36-a08c-a79b1cacbcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    california_housing.data,\n",
        "    california_housing.target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "last_test_data_point = X_test_scaled[-1]\n",
        "print(f'Last test data point: {last_test_data_point}')\n",
        "min_value = np.min(last_test_data_point)\n",
        "max_value = np.max(last_test_data_point)\n",
        "\n",
        "print(f'Minimum feature value of the last test data point: {min_value}')\n",
        "print(f'Maximum feature value of the last test data point: {max_value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe3tfp3NgSsP",
        "outputId": "6595a077-2a8a-465f-af64-67a0a2fb47cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last test data point: [-0.17259111 -0.92113763 -0.6058703  -0.14589658  0.21507676  0.05466644\n",
            " -0.66608108  0.60445493]\n",
            "Minimum feature value of the last test data point: -0.9211376319711084\n",
            "Maximum feature value of the last test data point: 0.6044549279675977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "train_data_shape = X_train_tensor.shape\n",
        "train_label_shape = y_train_tensor.shape\n",
        "\n",
        "print(f'Shape of train data tensor: {train_data_shape}')\n",
        "print(f'Shape of train label tensor: {train_label_shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrhTtd2bNPOM",
        "outputId": "5e07a003-a389-4b77-d08c-e6d8cbc9e9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data tensor: torch.Size([16512, 8])\n",
            "Shape of train label tensor: torch.Size([16512, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class RegressionANN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(RegressionANN, self).__init__()\n",
        "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
        "        self.hidden_layer = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.hidden_layer(x)\n",
        "        return x\n",
        "\n",
        "model = RegressionANN(input_dim=8, hidden_dim=16, output_dim=1)\n",
        "\n",
        "initial_bias = model.hidden_layer.bias.data\n",
        "print(f'Initial bias in the output layer: {initial_bias}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvtqSQ0dLlB2",
        "outputId": "1bc50280-3f9d-4c10-d54e-71ba1f5bb9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial bias in the output layer: tensor([0.2272])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "kl5_RIsiVYXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_predictions = model(X_train_tensor)\n",
        "initial_loss = loss_function(initial_predictions, y_train_tensor)\n",
        "print(f'Initial loss value: {initial_loss.item()}')"
      ],
      "metadata": {
        "id": "WePlHzzFVmPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9055ec1b-488e-4f84-ff1e-b9e774822f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss value: 4.202902793884277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train_tensor)\n",
        "    loss = loss_function(predictions, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "print(f'Loss value after 100 iterations: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMA35BbSg62v",
        "outputId": "19bdf15d-eb38-4130-eef4-4fe53088ee04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 2.333400011062622\n",
            "Epoch [20/100], Loss: 1.119511365890503\n",
            "Epoch [30/100], Loss: 0.8087179660797119\n",
            "Epoch [40/100], Loss: 0.728689432144165\n",
            "Epoch [50/100], Loss: 0.6494651436805725\n",
            "Epoch [60/100], Loss: 0.6001060009002686\n",
            "Epoch [70/100], Loss: 0.5567218661308289\n",
            "Epoch [80/100], Loss: 0.5240655541419983\n",
            "Epoch [90/100], Loss: 0.497019499540329\n",
            "Epoch [100/100], Loss: 0.4749816060066223\n",
            "Loss value after 100 iterations: 0.4749816060066223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RegressionANN_64(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(RegressionANN_64, self).__init__()\n",
        "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
        "        self.hidden_layer = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.hidden_layer(x)\n",
        "        return x\n",
        "\n",
        "model_64 = RegressionANN_64(input_dim=8, hidden_dim=64, output_dim=1)\n",
        "\n",
        "optimizer_64 = optim.Adam(model_64.parameters(), lr=0.01)\n",
        "loss_function_64 = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer_64.zero_grad()\n",
        "    predictions_64 = model_64(X_train_tensor)\n",
        "    loss_64 = loss_function_64(predictions_64, y_train_tensor)\n",
        "\n",
        "    loss_64.backward()\n",
        "    optimizer_64.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss_64.item()}')\n",
        "\n",
        "print(f'Loss value after 100 iterations with 64 hidden neurons: {loss_64.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-F70nQqhC_i",
        "outputId": "b1f135cb-d209-4fd0-9a11-a37b726fa418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.0591108798980713\n",
            "Epoch [20/100], Loss: 0.9692997336387634\n",
            "Epoch [30/100], Loss: 0.6826358437538147\n",
            "Epoch [40/100], Loss: 0.5752586126327515\n",
            "Epoch [50/100], Loss: 0.5252891778945923\n",
            "Epoch [60/100], Loss: 0.48318079113960266\n",
            "Epoch [70/100], Loss: 0.4564897418022156\n",
            "Epoch [80/100], Loss: 0.4391115605831146\n",
            "Epoch [90/100], Loss: 0.4262136220932007\n",
            "Epoch [100/100], Loss: 0.41575008630752563\n",
            "Loss value after 100 iterations with 64 hidden neurons: 0.41575008630752563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fxFig8B1hQkA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}